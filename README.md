# ETL Mini Project Overview
## Extract, Transform and Load


### Overview:
Welcome to the ETL Mini Project! In this collaborative endeavor, we master the art of building Extract, Transform, Load (ETL) pipelines using Python, Pandas, and either Python dictionary methods or regular expressions for data extraction and transformation.
 


### Table of Contents:
- Create Datframes , rename columns, change data types.
- Format date holding columns to datetime.
- Merge multiple dataframes.
- Drop unwanted columns.
- Export final dataframe  as csv file.
- Read contacts.xlsx from resources.
- Create dataframe.
- Extract the data from dataframe using regex.
- Convert data type to integer.
- Create copy of dataframe with selected columns.
- Split the columns further and reorder.
- Export the dataframe as CSV file.

### Create SQL Database
- Create the table schemas for each csv file using QuickDBD.
- Specify the data types, primary keys, foreign keys and other constraints.
- Save database schema as Postgres file.
- create a database 'crowd_funding_db' in postgres.
- Export all the dataframes to sql tables.

### Installation:
We used below libraries for our project:
1. Pandas library are used for the dataframe conversions and extractions. 
2. Numpy library are used to create columns for required entries in categories and subcategories dataframe.
3. Datetime library is used to convert string type data in columns to datetime format(YYY-MM-DD).  


### Usage:
This project reflects the way we can use the csv files to extract meaning full information and transform it into specific data types and columns and export into simple and clean format of csv file. Which can be further accessed in Postgres SQl and can be used to extract required information.

Screenshots added for reference from SQL queries.



### Contribution:
Group team: Anna Brabender, Qudsia Ahmad, Qianchen Ai and Lovepreet Singh.
Big thanks: Instructors: Tom seeber. 
